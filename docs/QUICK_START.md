# ğŸš€ **GENTLEMAN - Quick Start Guide**

> **ğŸ© Willkommen bei Gentleman!** Diese Anleitung bringt dich in wenigen Minuten zum Laufen.

---

## ğŸ“‹ **Voraussetzungen**

### ğŸ–¥ï¸ **Hardware Requirements**
- **RX PC**: AMD RX 6700 XT (oder kompatible GPU) fÃ¼r LLM-Server
- **M1 Mac**: Apple Silicon fÃ¼r STT/TTS Services
- **i7 MacBook**: Client-GerÃ¤t (optional)
- **Netzwerk**: Stabile Internetverbindung fÃ¼r Mesh-VPN

### ğŸ’» **Software Requirements**
- **Docker** & **Docker Compose**
- **Python 3.9+**
- **Git**
- **Make** (fÃ¼r elegante Commands)

---

## âš¡ **One-Click Installation**

```bash
# ğŸ© Gentleman herunterladen und installieren
curl -sSL https://raw.githubusercontent.com/user/gentleman/main/setup.sh | bash

# ğŸ“ In Projekt-Verzeichnis wechseln
cd gentleman

# ğŸ”§ Konfiguration anpassen (optional)
cp env.example .env
nano .env  # Anpassungen vornehmen
```

---

## ğŸš€ **Services Starten**

### ğŸ¯ **Alle Services auf einmal**
```bash
# ğŸ© Gentleman komplett starten
make gentleman-up

# ğŸ“Š Status prÃ¼fen
make gentleman-status

# ğŸ“ Live Logs anzeigen
make gentleman-logs
```

### ğŸ”§ **Einzelne Services**
```bash
# ğŸ–¥ï¸ Nur LLM Server (RX PC)
docker-compose up -d llm-server

# ğŸ¤ Nur STT Service (M1 Mac)
docker-compose up -d stt-service

# ğŸ—£ï¸ Nur TTS Service (M1 Mac)
docker-compose up -d tts-service

# ğŸŒ Nur Mesh Coordinator
docker-compose up -d mesh-coordinator
```

---

## ğŸŒ **Nebula Mesh Network Setup**

### ğŸ  **Lighthouse (Zentraler Knoten)**
```bash
# ğŸ” Zertifikate generieren
cd nebula/lighthouse
nebula-cert ca -name "Gentleman Mesh CA"

# ğŸŒ Lighthouse starten
nebula -config config.yml
```

### ğŸ–¥ï¸ **RX Node (LLM Server)**
```bash
# ğŸ” Node-Zertifikat erstellen
nebula-cert sign -name "rx-node" -ip "192.168.100.10/24"

# ğŸŒ Node verbinden
cd ../rx-node
nebula -config config.yml
```

### ğŸ **M1 Node (STT/TTS)**
```bash
# ğŸ” Node-Zertifikat erstellen
nebula-cert sign -name "m1-node" -ip "192.168.100.20/24"

# ğŸŒ Node verbinden
cd ../m1-node
nebula -config config.yml
```

---

## ğŸ§ª **Erste Tests**

### ğŸ” **Health Checks**
```bash
# ğŸ¥ Alle Services prÃ¼fen
make gentleman-health

# ğŸ–¥ï¸ LLM Server testen
curl http://172.20.1.10:8000/health

# ğŸ¤ STT Service testen
curl http://172.20.1.20:8000/health

# ğŸ—£ï¸ TTS Service testen
curl http://172.20.1.30:8000/health
```

### ğŸ¯ **API Tests**
```bash
# ğŸ§  LLM Generation testen
curl -X POST http://172.20.1.10:8000/generate \
  -H "Content-Type: application/json" \
  -d '{"prompt": "Hallo, wie geht es dir?", "max_tokens": 100}'

# ğŸ¤ STT Test (mit Audio-Datei)
curl -X POST http://172.20.1.20:8000/transcribe \
  -F "audio=@test_audio.wav"

# ğŸ—£ï¸ TTS Test
curl -X POST http://172.20.1.30:8000/synthesize \
  -H "Content-Type: application/json" \
  -d '{"text": "Hallo, das ist ein Test!", "voice": "default"}'
```

---

## ğŸŒ **Web Interface**

### ğŸ“± **Browser Ã¶ffnen**
```bash
# ğŸŒ Web Interface starten
make gentleman-web

# ğŸ”— Im Browser Ã¶ffnen
open http://localhost:8080
# oder
xdg-open http://localhost:8080
```

### ğŸ›ï¸ **Dashboard Features**
- **ğŸ¤ Voice Input**: Spracheingabe direkt im Browser
- **ğŸ§  AI Chat**: Interaktion mit LLM
- **ğŸ—£ï¸ Voice Output**: Sprachausgabe mit Emotionen
- **ğŸ“Š Monitoring**: Live-Status aller Services
- **âš™ï¸ Settings**: Konfiguration anpassen

---

## ğŸ“Š **Monitoring & Observability**

### ğŸ“ˆ **Prometheus Metrics**
```bash
# ğŸ“Š Prometheus Ã¶ffnen
open http://localhost:9090
```

### ğŸ“Š **Grafana Dashboards**
```bash
# ğŸ“Š Grafana Ã¶ffnen
open http://localhost:3000

# ğŸ”‘ Login
# Username: gentleman
# Password: gentleman123
```

### ğŸ“ **Log Aggregation**
```bash
# ğŸ“ Logs in Echtzeit
make gentleman-logs

# ğŸ” Spezifische Service Logs
docker-compose logs -f llm-server
docker-compose logs -f stt-service
docker-compose logs -f tts-service
```

---

## ğŸ¯ **Typische Workflows**

### ğŸ—£ï¸ **Voice-to-Voice Pipeline**
1. **ğŸ¤ Audio aufnehmen** â†’ STT Service (M1 Mac)
2. **ğŸ“ Text verarbeiten** â†’ LLM Server (RX PC)
3. **ğŸ—£ï¸ Antwort generieren** â†’ TTS Service (M1 Mac)
4. **ğŸ”Š Audio ausgeben** â†’ Client

### ğŸ’¬ **Chat Interface**
1. **ğŸ“± Web Interface Ã¶ffnen**
2. **ğŸ’¬ Text eingeben oder Sprache aufnehmen**
3. **ğŸ§  AI-Antwort erhalten**
4. **ğŸ—£ï¸ Antwort anhÃ¶ren**

### ğŸ“Š **System Monitoring**
1. **ğŸ“ˆ Grafana Dashboard Ã¶ffnen**
2. **ğŸ“Š Metriken Ã¼berwachen**
3. **ğŸš¨ Alerts konfigurieren**
4. **ğŸ”§ Performance optimieren**

---

## ğŸ”§ **Troubleshooting**

### âŒ **HÃ¤ufige Probleme**

#### ğŸ³ **Docker Issues**
```bash
# ğŸ”„ Docker neu starten
sudo systemctl restart docker

# ğŸ§¹ Docker aufrÃ¤umen
make gentleman-cleanup
```

#### ğŸŒ **Nebula Connection Issues**
```bash
# ğŸ” Nebula Status prÃ¼fen
nebula -config nebula/rx-node/config.yml -test

# ğŸ”„ Nebula neu starten
sudo systemctl restart nebula
```

#### ğŸ–¥ï¸ **GPU Issues (RX 6700 XT)**
```bash
# ğŸ” ROCm Status prÃ¼fen
rocm-smi

# ğŸ”§ GPU Treiber neu laden
sudo modprobe -r amdgpu && sudo modprobe amdgpu
```

#### ğŸ **M1 Mac Issues**
```bash
# ğŸ” MPS Status prÃ¼fen
python -c "import torch; print(torch.backends.mps.is_available())"

# ğŸ”§ Rosetta fÃ¼r x86 KompatibilitÃ¤t
arch -x86_64 /bin/bash
```

### ğŸ“ **Support**
- **ğŸ“š Dokumentation**: `./docs/`
- **ğŸ› Issues**: GitHub Issues
- **ğŸ’¬ Community**: Discord Server
- **ğŸ“§ Email**: support@gentleman-ai.com

---

## ğŸ¯ **NÃ¤chste Schritte**

### ğŸ“– **Weitere Dokumentation**
- **ğŸ—ï¸ [Architecture Guide](ARCHITECTURE.md)** - System-Architektur verstehen
- **ğŸ”§ [Configuration Guide](CONFIGURATION.md)** - Erweiterte Konfiguration
- **ğŸŒ [Nebula Setup](NEBULA_SETUP.md)** - Mesh-VPN im Detail
- **ğŸ³ [Docker Guide](DOCKER_GUIDE.md)** - Container-Deployment
- **ğŸ“Š [Performance Guide](PERFORMANCE.md)** - Optimierung & Tuning

### ğŸš€ **Advanced Features**
- **ğŸ­ Emotion Analysis** - Emotionale Sprachsynthese
- **ğŸŒ Multi-Language** - Mehrsprachige UnterstÃ¼tzung
- **ğŸ“± Mobile Apps** - Native iOS/Android Clients
- **ğŸ”Œ API Integration** - Eigene Anwendungen entwickeln
- **â˜ï¸ Cloud Deployment** - Skalierung in die Cloud

---

> **ğŸ© Herzlichen GlÃ¼ckwunsch!** Du hast Gentleman erfolgreich eingerichtet.  
> **ğŸŒŸ Viel SpaÃŸ mit deiner eleganten, verteilten KI-Pipeline!**

---

**ğŸ“… Letzte Aktualisierung**: $(date)  
**ğŸ“‹ Version**: 1.0.0  
**ğŸ”„ Status**: Production Ready 