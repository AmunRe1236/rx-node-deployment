# ğŸš€ GENTLEMAN Dynamic Cluster Deployment

Automatisches Deployment-System fÃ¼r GENTLEMAN Cluster Nodes mit optimierter AI-Inferenz

## ğŸ¯ Node-spezifische Installation

### ğŸ® RX Node (GPU-beschleunigt)
```bash
# 1. Repository klonen
git clone https://github.com/AmunRe1236/rx-node-deployment.git
cd rx-node-deployment

# 2. RX Node Deployment starten
chmod +x quick_rx_deployment.sh
./quick_rx_deployment.sh
```

### ğŸ–¥ï¸ i7 Node (CPU-optimiert)
```bash
# 1. Repository klonen (gleiche Quelle)
git clone https://github.com/AmunRe1236/rx-node-deployment.git
cd rx-node-deployment

# 2. i7 Node Deployment starten
chmod +x i7_node_deployment.sh
./i7_node_deployment.sh
```

## ğŸ® RX Node - GPU-beschleunigt

### Was wird installiert:
- âœ… **AMD ROCm GPU-Treiber** fÃ¼r GPU-Beschleunigung
- âœ… **LM Studio v0.2.29** mit GPU-Support  
- âœ… **Firewall-Konfiguration** (Port 1234)
- âœ… **Systemd Auto-Start Service**
- âœ… **GPU-Test-Skripte**

### Nach dem Deployment:
1. **LM Studio starten**: `./start_lm_studio.sh`
2. **Modell downloaden** (empfohlen: deepseek-r1-7b)
3. **Server aktivieren** auf Port 1234 mit GPU
4. **â¡ï¸ GPU-LÃ¼fter werden hÃ¶rbar sein! ğŸ®**

## ğŸ–¥ï¸ i7 Node - CPU-optimiert

### Was wird installiert:
- âœ… **Intel MKL** fÃ¼r CPU-Optimierung
- âœ… **OpenBLAS & OpenMP** fÃ¼r Multi-Threading
- âœ… **LM Studio v0.2.29** mit CPU-Optimierungen
- âœ… **Firewall-Konfiguration** (Port 1235)
- âœ… **Systemd Auto-Start Service**
- âœ… **CPU-Performance-Tests**

### Nach dem Deployment:
1. **LM Studio starten**: `cd ~/i7-lmstudio && ./start_i7_lmstudio.sh`
2. **Modell downloaden** (empfohlen: < 7B Parameter, quantisiert)
3. **Server aktivieren** auf Port 1235 mit CPU-Optimierung
4. **â¡ï¸ CPU wird bei Inferenz voll ausgelastet! ğŸ§ **

## ğŸ“‹ Deployment-Optionen:

### RX Node (GPU):
```bash
# VollstÃ¤ndiges GPU-Deployment
./quick_rx_deployment.sh

# Kompaktes GPU-Deployment  
./rx_deployment_direct.sh

# Direkter Befehl (siehe rx_direct_deploy_command.txt)
```

### i7 Node (CPU):
```bash
# VollstÃ¤ndiges CPU-Deployment
./i7_node_deployment.sh
```

## ğŸ§ª Node-spezifische Testsuites:

### ğŸ® RX Node Testsuite:
```bash
chmod +x test_rx_node.sh
./test_rx_node.sh
```

**RX Node Test-Bereiche:**
- ğŸ–¥ï¸  **System Information** - Hardware & OS Details
- ğŸ® **AMD GPU Detection** - GPU Hardware-Erkennung
- ğŸ”§ **ROCm Installation** - GPU-Treiber & Tools
- ğŸ¤– **LM Studio Installation** - Binary & Version Check
- ğŸŒ **Network Connectivity** - IP & Port VerfÃ¼gbarkeit (1234)
- ğŸ”— **LM Studio API Test** - API Endpoint VerfÃ¼gbarkeit
- âš¡ **GPU Inference Performance** - Echte AI-Inferenz mit Timing
- ğŸ“Š **System Resources** - CPU, RAM, GPU-Temperatur

### ğŸ–¥ï¸ i7 Node Testsuite:
```bash
chmod +x test_i7_node.sh
./test_i7_node.sh
```

**i7 Node Test-Bereiche:**
- ğŸ“‹ **System Information** - Hardware & Node-Validierung
- ğŸ§  **Intel CPU Detection** - CPU Features (AVX2, AVX-512, FMA)
- ğŸ”§ **CPU Optimization Libraries** - Intel MKL, OpenBLAS, OpenMP
- ğŸ¤– **i7 LM Studio Installation** - i7-spezifische Installation
- ğŸŒ **Network & Port Configuration** - Port 1235 & Konflikt-Check
- ğŸ”— **i7 LM Studio API Test** - i7-spezifische API Tests
- âš¡ **CPU Inference Performance** - CPU-Inferenz mit Monitoring
- ğŸ“Š **System Resources & Temperature** - CPU-Monitoring
- ğŸ”§ **i7 Service Status** - Systemd Service Check

### Test-Ergebnisse:
- âœ… **RX Node Ziele**: <30s GPU-Inferenz, GPU-Beschleunigung aktiv
- âœ… **i7 Node Ziele**: <60s CPU-Inferenz, Intel-Optimierungen aktiv
- ğŸ“ˆ **Detaillierte Logs**: VollstÃ¤ndige Diagnose-Informationen

## ğŸŒ Server URLs nach Installation:

### ğŸ® RX Node (GPU):
- **LM Studio API**: `http://192.168.68.117:1234`
- **Models Endpoint**: `http://192.168.68.117:1234/v1/models`
- **Chat Completions**: `http://192.168.68.117:1234/v1/chat/completions`

### ğŸ–¥ï¸ i7 Node (CPU):
- **LM Studio API**: `http://[i7-node-ip]:1235`
- **Models Endpoint**: `http://[i7-node-ip]:1235/v1/models`
- **Chat Completions**: `http://[i7-node-ip]:1235/v1/chat/completions`

## ğŸ§ª Legacy GPU-Test:

RX Node Python-Test (zusÃ¤tzlich zur Testsuite):
```bash
python3 test_gpu_inference.py
```

## ğŸ“Š Performance-Vergleich:

| Node Type | Hardware | Port | Target Response | Modell-Empfehlung |
|-----------|----------|------|-----------------|-------------------|
| ğŸ® **RX Node** | AMD GPU + ROCm | 1234 | < 30s | Alle GrÃ¶ÃŸen, GPU-optimiert |
| ğŸ–¥ï¸ **i7 Node** | Intel CPU + MKL | 1235 | < 60s | < 7B Parameter, quantisiert |

## ğŸ”§ Node-Erkennung:

Die Skripte erkennen automatisch den Node-Typ:
- **RX Node**: IP 192.168.68.117 â†’ GPU-Deployment
- **i7 Node**: Andere IPs â†’ CPU-Deployment
- **Schutz**: Verhindert versehentliche Fehl-Deployments

---

**GENTLEMAN Dynamic Cluster System**  
- ğŸ® RX Node (192.168.68.117) - GPU AI Inference Engine  
- ğŸ–¥ï¸ i7 Node(s) - CPU AI Inference Engines 