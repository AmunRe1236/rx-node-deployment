# ğŸš€ GENTLEMAN RX Node Deployment

Automatisches Deployment-System fÃ¼r RX Node mit AMD GPU-Beschleunigung

## ğŸ¯ Schnelle Installation

```bash
# 1. Repository klonen
git clone https://github.com/AmunRe1236/rx-node-deployment.git
cd rx-node-deployment

# 2. Deployment starten
chmod +x quick_rx_deployment.sh
./quick_rx_deployment.sh
```

## ğŸ® Was wird installiert:

- âœ… **AMD ROCm GPU-Treiber** fÃ¼r GPU-Beschleunigung
- âœ… **LM Studio v0.2.29** mit GPU-Support  
- âœ… **Firewall-Konfiguration** (Port 1234)
- âœ… **Systemd Auto-Start Service**
- âœ… **GPU-Test-Skripte**

## ğŸ”Š Nach dem Deployment:

1. **LM Studio starten**: `./start_lm_studio.sh`
2. **Modell downloaden** (empfohlen: deepseek-r1-7b)
3. **Server aktivieren** auf Port 1234 mit GPU
4. **â¡ï¸ GPU-LÃ¼fter werden hÃ¶rbar sein! ğŸ®**

## ğŸ“‹ Deployment-Optionen:

### Option 1: VollstÃ¤ndiges Deployment
```bash
./quick_rx_deployment.sh
```

### Option 2: Kompaktes Deployment  
```bash
./rx_deployment_direct.sh
```

### Option 3: Direkter Befehl
```bash
# Siehe rx_direct_deploy_command.txt
```

## ğŸ§ª RX Node Testsuite:

**Nach dem Deployment die komplette Testsuite ausfÃ¼hren:**
```bash
chmod +x test_rx_node.sh
./test_rx_node.sh
```

### Test-Bereiche:
- ğŸ–¥ï¸  **System Information** - Hardware & OS Details
- ğŸ® **AMD GPU Detection** - GPU Hardware-Erkennung
- ğŸ”§ **ROCm Installation** - GPU-Treiber & Tools
- ğŸ¤– **LM Studio Installation** - Binary & Version Check
- ğŸŒ **Network Connectivity** - IP & Port VerfÃ¼gbarkeit
- ğŸ”— **LM Studio API Test** - API Endpoint VerfÃ¼gbarkeit
- âš¡ **GPU Inference Performance** - Echte AI-Inferenz mit Timing
- ğŸ“Š **System Resources** - CPU, RAM, Temperatur Monitoring

### Test-Ergebnisse:
- âœ… **Erfolgs-Rate**: Percentage der erfolgreichen Tests
- ğŸ¯ **Performance-Ziele**: <30s Antwortzeit fÃ¼r Inferenz
- ğŸ“ˆ **Detaillierte Logs**: VollstÃ¤ndige Diagnose-Informationen

## ğŸŒ Server URLs nach Installation:

- **LM Studio API**: `http://192.168.68.117:1234`
- **Models Endpoint**: `http://192.168.68.117:1234/v1/models`
- **Chat Completions**: `http://192.168.68.117:1234/v1/chat/completions`

## ğŸ§ª GPU-Test:

Nach der Installation:
```bash
python3 test_gpu_inference.py
```

Erwartete Ergebnisse:
- âš¡ Antwortzeit: <30 Sekunden
- ğŸš€ Token-Rate: >15 tokens/sec
- ğŸ”Š **GPU-LÃ¼fter hÃ¶rbar wÃ¤hrend Inferenz**

---

**GENTLEMAN Dynamic Cluster System**  
RX Node (192.168.68.117) - AI Inference Engine 